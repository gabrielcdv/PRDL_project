# Predicting Air Quality in Barcelona (MLLB Report)

This repository contains the code, data processing codes, and experimental results for the Predicting Air Quality in Barcelona project, conducted as a report for the MLLB (Machine Learning Laboratory) course.

The goal of this project is to develop and evaluate deep learning models (and compare them with classical machine learning approaches) to predict hourly air quality (specifically PM10 concentrations) hours in the future across Barcelona.

This project includes:
- A dataset creation notebook : Code for gathering, cleaning, and merging large datasets from the Barcelona OpenData portal and the Open-Meteo API, including:

  - Hourly Air Quality measurements from 8 stations.

  - Hourly Road Traffic Density from hundreds of sections, aggregated into a configurable city grid.

  - Hourly Weather Data (temperature, wind, precipitation, etc.).

- Exploratory Data Analysis (EDA): Detailed analysis confirming data health, identifying sensor anomalies, and establishing correlations between traffic, weather, and air pollution.

- Model Implementation:

  - Classical Machine Learning: Gradint Boosting for initial traffic prediction.

  - Deep Learning (DL) Models: Sequential Dense Neural Networks for predicting air quality régression and classification targets.

# Files in this repository

## Important files
| File | Use |
| --- | --- |
| *`dataset_creation.ipynb` | Creates the dataset files (regression and classification) used by `exploratory_data_analysis.ipynb`. |
| *`exploratory_data_analysis.ipynb `| Performs the EDA, and cleans the datasets accordingly, creating the final datasets, used by all next notebooks.|
| *`regression_main.ipynb` | Train and test a regression model to predict traffic, and another to predict PM10 concentration in the air, with 12 hours overhead |
| `regression_data_balancing.ipynb` | Same as the above except that training data is only hours with pollution >50µg/m³ and 24h coninous hours before the spike |
| `regression_data_balancing2.ipynb` | Same as the above except that I added back some "normal" data to the training dataset to make it more balanced |
| *`classification_main.ipynb` | Similar to the previous one, the traffic predictor is unchanged, the air quality model is now using labels |
| `classification_data_balancing.ipynb` | Same idea as for the regression data balancing but for classification |
| `classification_weigth_balancing.ipynb` | Instead of tweaking the training dataset, I attached weigths to the classes to counterbalance their uneven distribution |
| *`deep_learning_naive.ipynb` | Train and test a deep learning model to predict traffic, and another to predict PM10 concentration in the air, with 12 hours overhead, using a feed-forward NN with lags and rolls in the dataset (my first, naive experiment)|
| `deep_learning_GRU.ipynb` | Train and test a deep learning model to predict traffic, and another to predict PM10 concentration in the air, with 12 hours overhead, using GRU that is more adapted to time series and a version of the dataset whithout lags and rolls. |

The files marked with '*' are those I consider the most important, as the other files are modified version of them.


## Files of lesser importance
Some of these files are just remainings of experiments, some were generated by ChatGPT or other LLMs to explore new ideas quickly.
| File | Use |
| --- | --- |
| `dataset_creation_better_ramusage.ipynb` | This file is a modified (by ChatGPT) version of `dataset_creation.ipynb` that uses less RAM and allowed me to build dataset from January 2023 to December 2024 (files `created_dataset.pkl` and `created_dataset_classes.pkl`) |
| `regression_grid_search.ipynb` and `regression_grid_search2.ipynb` | These files may be outdated, they were just an experiment were I tried all sorts of models and hyperparameters for these models, however the results are not really interesting, this is why I stuck with LightGBM |

I also included directly in the repository the `.pkl` files, so it is not mandatory to run the first two notebooks.

## Technical details
This project was written on my personal computer using Python 3.13.7.
The first notebook **cannot** be executed on Google Colab because it downloads data from Barcelona's OpenData server, which blocks requests from Colab machines. The other notebooks should run fine as the datasets files are included in the repository.

